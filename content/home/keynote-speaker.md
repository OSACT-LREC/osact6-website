---
widget: blank
headless: true

# ... Put Your Section Options Here (title etc.) ...
title: Keynote Speaker
subtitle:
weight: 70  # section position on page
design:
  # Choose how many columns the section has. Valid values: 1 or 2.
  columns: '1'
---
<div class="container">
  <div class="row">
    <div class="col-md-6 mx-auto hero-media">
      <a>
        <img src="https://blockchain.ubc.ca/sites/default/files/styles/square_400/public/profile-images/2022-12/Muhammad-Abdul-Mageed-UBC-iSchool%20%281%29.jpg?itok=cwm3B5JW"
          alt="OSACT6 Image" class="img-fluid rounded-circle" style="max-width: 100%;">
      </a>
    </div>
  </div>
</div>
<div class="container">
  <div class="row">
    <div class="col-lg-8 mx-auto text-center">
      <p class="lead" style="font-size: 1rem;">
        <br>
        <b><b>Muhammad Abdul-Mageed, University of British Columbia, Canada</b><br><br>
        <b>Title: </b><br>Towards Arab-Centric Large Language Models<br><br>
        <b>Abstract:</b></b><br>
<p align="justify">The landscape of large language models (LLMs) is rapidly evolving, yet it continues to face significant challenges in computational efficiency and energy usage. Arabic-centric LLMs are particularly fraught with issues such as inadequate evaluations, cultural insensitivity, insufficient representation of the wide array of Arabic dialects, an absence of multimodal capabilities, designs that are too generic for specialized domains, and a disconnection from other low-resource languages. These problems are compounded by a general lack of detailed knowledge about the Arabic capabilities of existing LLMs. In this talk, we address these challenges by developing a host of models capable of understanding and generating content in a broad spectrum of Arabic languages and dialects. In particular, we present a suite of generative models tailored for text, speech, and image generation, designed to support and enhance the representation of Arabic in several domains. Our approach leverages cutting-edge machine learning methods and large-scale, diverse datasets to ensure our models achieve both high accuracy and cultural relevance. By focusing on critical areas such as archival work, cultural heritage and preservation, financial services, healthcare delivery, and education, our work aims to bridge the linguistic digital divide and foster equitable AI benefits. We discuss the methods we employ, the challenges we encounter, the solutions we propose, and the broader implications of our efforts. </p>
<br>
<b>Bio:</b></b><br>
<p align="justify">Muhammad Abdul-Mageed is a Canada Research Chair in Natural Language Processing and Machine Learning, and Associate Professor with appointments in the School of Information, and the Departments of Linguistics and Computer Science at The University of British Columbia. He is also a Visiting Associate Professor at MBZUAI. His research is in deep learning and natural language processing, focusing on large language models in multilingual contexts, with a goal to innovate more equitable, efficient, and ‘social’ machines for improved human health, more engaging learning, safer social networking, and reduced information overload. Applications of his work span a wide range of areas across speech, language, and vision. He is director of the UBC Deep Learning & NLP Group, co-director of the SSHRC-funded I Trust Artificial Intelligence, and co-lead of the Ensuring Full Literacy Partnership. He is a founding member of the UBC Center for Artificial Intelligence Decision making and Action and a member of the Institute for Computing, Information, and Cognitive Systems. His work has been supported by Google, AMD, Amazon, Natural Sciences and Engineering Research Council of Canada, Social Sciences and Humanities Research Council of Canada, Canada Foundation for Innovation, and Digital Research Alliance of Canada.  </p>    
</p>
    </div>
  </div>
</div>

</div>            